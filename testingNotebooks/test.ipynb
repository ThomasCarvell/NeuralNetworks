{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def a(*args):\n",
    "    if len(args) == 1: \n",
    "        return np.array(args[0])\n",
    "    else:\n",
    "        return np.array(args)\n",
    "\n",
    "def relu(x):\n",
    "    if x > 0:\n",
    "        return x\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "def reluderiv(x):\n",
    "    if x > 0:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "def no(x):\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def propagate(input,weights,biases,activation):\n",
    "    output = np.dot(input,weights) + biases\n",
    "    for i in range(len(output)):\n",
    "        output[i] = activation(output[i])\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rand(size):\n",
    "    return np.random.normal(size=size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class network:\n",
    "    def __init__(self, layers):\n",
    "        self.layers = layers\n",
    "        self.weights = []\n",
    "        self.biases = []\n",
    "\n",
    "        for i in range(len(layers)-1):\n",
    "            self.biases.append(rand(layers[i+1]))\n",
    "\n",
    "        for i in range(len(layers)-1):\n",
    "            self.weights.append(rand((layers[i],layers[i+1])))\n",
    "\n",
    "    def saveModel(self,filename):\n",
    "        with open(filename,'wb+') as f:\n",
    "            f.write(pickle.dumps(self.layers) + b\"\\n\")\n",
    "            f.write(pickle.dumps(self.weights) + b\"\\n\")\n",
    "            f.write(pickle.dumps(self.biases) + b\"\\n\")\n",
    "\n",
    "    def loadModel(self,filename):\n",
    "        with open(filename,\"rb\") as f:\n",
    "            self.layers = pickle.loads(f.readline()[:-1])\n",
    "            self.weights = pickle.loads(f.readline()[:-1])\n",
    "            self.biases = pickle.loads(f.readline()[:-1])\n",
    "\n",
    "    def propagate(self,inp):\n",
    "        activations = [inp]\n",
    "        values = [inp]\n",
    "        current = inp\n",
    "        for i in range(len(self.layers)-1):\n",
    "            current = propagate(current,self.weights[i], self.biases[i],no)\n",
    "\n",
    "            values.append(current.copy())\n",
    "            for i in range(len(current)):\n",
    "                current[i] = relu(current[i])\n",
    "            activations.append(current.copy())\n",
    "\n",
    "        return current,activations,values\n",
    "\n",
    "    def calculateErrors(self,inp,target):\n",
    "        output,activations,values = self.propagate(inp)\n",
    "        cost = sum((output-target)**2)\n",
    "        errors = [(output-target) * a([reluderiv(values[-1][i]) for i in range(len(values[-1]))])]\n",
    "\n",
    "\n",
    "        for i in range(len(self.layers)-1):\n",
    "\n",
    "            weights = self.weights[-(i+1)].T\n",
    "            previousErrors = errors[0]\n",
    "            derivActivation = a([reluderiv(values[-(i+2)][j]) for j in range(len(values[-(i+2)]))])\n",
    "\n",
    "            errors.insert(0,(np.dot(previousErrors,weights) * derivActivation))\n",
    "\n",
    "        print(errors)\n",
    "        print(values)\n",
    "\n",
    "        biasDeriv = errors.copy()\n",
    "\n",
    "        weightDeriv = []\n",
    "\n",
    "        for i in range(len(self.layers)-1):\n",
    "            weightDeriv.append(np.zeros((self.layers[i],self.layers[i+1])))\n",
    "            \n",
    "            for fn in range(self.layers[i]):\n",
    "                for tn in range(self.layers[i+1]):\n",
    "                    weightDeriv[-1][fn][tn] = activations[i][fn] * errors[i+1][tn]\n",
    "\n",
    "        return errors,biasDeriv,weightDeriv\n",
    "    \n",
    "    def tweakNetwork(self, learnFactor, biasDeriv, weightDeriv):\n",
    "        for i in range(len(self.layers)-1):\n",
    "            self.weights[i] -= weightDeriv[i]*learnFactor\n",
    "\n",
    "        #print(biasDeriv)\n",
    "        #print(self.biases)\n",
    "\n",
    "        for i in range(len(self.layers)-1):\n",
    "            self.biases[i] += learnFactor * biasDeriv[1:][i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[0.14974665]])]\n",
      "[array([0.06429983])]\n",
      "(array([[0.21404648]]), [1, array([[0.21404648]])], [1, array([[0.21404648]])])\n",
      "[array([-0.26744055]), array([-1.78595352])]\n",
      "[[1], array([0.21404648])]\n",
      "([array([-0.26744055]), array([-1.78595352])], [array([-0.26744055]), array([-1.78595352])], [array([[-1.78595352]])])\n"
     ]
    }
   ],
   "source": [
    "n = network([])\n",
    "\n",
    "n.loadModel(\"test2.net\")\n",
    "\n",
    "print(n.weights)\n",
    "print(n.biases)\n",
    "\n",
    "print(n.propagate(1))\n",
    "\n",
    "print(n.calculateErrors([1],[2]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1e34f4041224984483483a0ab98a959c84b5eb2e5dd93018c41185f6faee2159"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
